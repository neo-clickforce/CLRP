{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c0d5f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:17.882390Z",
     "iopub.status.busy": "2021-08-03T07:07:17.880401Z",
     "iopub.status.idle": "2021-08-03T07:07:18.133766Z",
     "shell.execute_reply": "2021-08-03T07:07:18.134638Z",
     "shell.execute_reply.started": "2021-08-03T06:24:55.822527Z"
    },
    "papermill": {
     "duration": 0.273838,
     "end_time": "2021-08-03T07:07:18.134977",
     "exception": false,
     "start_time": "2021-08-03T07:07:17.861139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/merges.txt\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/vocab.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/tokenizer_config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/pytorch_model.bin\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/special_tokens_map.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large-mnli/added_tokens.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/merges.txt\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/vocab.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/tokenizer_config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/pytorch_model.bin\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/special_tokens_map.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-base/added_tokens.json\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/merges.txt\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/vocab.json\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/tokenizer_config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/pytorch_model.bin\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/special_tokens_map.json\n",
      "/kaggle/input/roberta-transformers-pytorch/distilroberta-base/added_tokens.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/merges.txt\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/vocab.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/tokenizer_config.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/pytorch_model.bin\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/special_tokens_map.json\n",
      "/kaggle/input/roberta-transformers-pytorch/roberta-large/added_tokens.json\n",
      "/kaggle/input/clrp-models/submission.csv\n",
      "/kaggle/input/clrp-models/atHead_model3/model.bin\n",
      "/kaggle/input/clrp-models/atHead_model3/merges.txt\n",
      "/kaggle/input/clrp-models/atHead_model3/tokenizer.json\n",
      "/kaggle/input/clrp-models/atHead_model3/vocab.json\n",
      "/kaggle/input/clrp-models/atHead_model3/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atHead_model3/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atPool_model2/model.bin\n",
      "/kaggle/input/clrp-models/atPool_model2/merges.txt\n",
      "/kaggle/input/clrp-models/atPool_model2/tokenizer.json\n",
      "/kaggle/input/clrp-models/atPool_model2/vocab.json\n",
      "/kaggle/input/clrp-models/atPool_model2/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atPool_model2/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/concat_model1/model.bin\n",
      "/kaggle/input/clrp-models/concat_model1/merges.txt\n",
      "/kaggle/input/clrp-models/concat_model1/tokenizer.json\n",
      "/kaggle/input/clrp-models/concat_model1/vocab.json\n",
      "/kaggle/input/clrp-models/concat_model1/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/concat_model1/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/concat_model0/model.bin\n",
      "/kaggle/input/clrp-models/concat_model0/merges.txt\n",
      "/kaggle/input/clrp-models/concat_model0/tokenizer.json\n",
      "/kaggle/input/clrp-models/concat_model0/vocab.json\n",
      "/kaggle/input/clrp-models/concat_model0/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/concat_model0/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atPool_model4/model.bin\n",
      "/kaggle/input/clrp-models/atPool_model4/merges.txt\n",
      "/kaggle/input/clrp-models/atPool_model4/tokenizer.json\n",
      "/kaggle/input/clrp-models/atPool_model4/vocab.json\n",
      "/kaggle/input/clrp-models/atPool_model4/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atPool_model4/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atHead_model1/model.bin\n",
      "/kaggle/input/clrp-models/atHead_model1/merges.txt\n",
      "/kaggle/input/clrp-models/atHead_model1/tokenizer.json\n",
      "/kaggle/input/clrp-models/atHead_model1/vocab.json\n",
      "/kaggle/input/clrp-models/atHead_model1/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atHead_model1/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atPool_model1/model.bin\n",
      "/kaggle/input/clrp-models/atPool_model1/merges.txt\n",
      "/kaggle/input/clrp-models/atPool_model1/tokenizer.json\n",
      "/kaggle/input/clrp-models/atPool_model1/vocab.json\n",
      "/kaggle/input/clrp-models/atPool_model1/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atPool_model1/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/concat_model2/model.bin\n",
      "/kaggle/input/clrp-models/concat_model2/merges.txt\n",
      "/kaggle/input/clrp-models/concat_model2/tokenizer.json\n",
      "/kaggle/input/clrp-models/concat_model2/vocab.json\n",
      "/kaggle/input/clrp-models/concat_model2/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/concat_model2/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atHead_model2/model.bin\n",
      "/kaggle/input/clrp-models/atHead_model2/merges.txt\n",
      "/kaggle/input/clrp-models/atHead_model2/tokenizer.json\n",
      "/kaggle/input/clrp-models/atHead_model2/vocab.json\n",
      "/kaggle/input/clrp-models/atHead_model2/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atHead_model2/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atHead_model0/model.bin\n",
      "/kaggle/input/clrp-models/atHead_model0/merges.txt\n",
      "/kaggle/input/clrp-models/atHead_model0/tokenizer.json\n",
      "/kaggle/input/clrp-models/atHead_model0/vocab.json\n",
      "/kaggle/input/clrp-models/atHead_model0/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atHead_model0/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/concat_model4/model.bin\n",
      "/kaggle/input/clrp-models/concat_model4/merges.txt\n",
      "/kaggle/input/clrp-models/concat_model4/tokenizer.json\n",
      "/kaggle/input/clrp-models/concat_model4/vocab.json\n",
      "/kaggle/input/clrp-models/concat_model4/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/concat_model4/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atHead_model4/model.bin\n",
      "/kaggle/input/clrp-models/atHead_model4/merges.txt\n",
      "/kaggle/input/clrp-models/atHead_model4/tokenizer.json\n",
      "/kaggle/input/clrp-models/atHead_model4/vocab.json\n",
      "/kaggle/input/clrp-models/atHead_model4/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atHead_model4/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atPool_model3/model.bin\n",
      "/kaggle/input/clrp-models/atPool_model3/merges.txt\n",
      "/kaggle/input/clrp-models/atPool_model3/tokenizer.json\n",
      "/kaggle/input/clrp-models/atPool_model3/vocab.json\n",
      "/kaggle/input/clrp-models/atPool_model3/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atPool_model3/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/scaler/scaler_fold2\n",
      "/kaggle/input/clrp-models/scaler/scaler_fold4\n",
      "/kaggle/input/clrp-models/scaler/scaler_fold1\n",
      "/kaggle/input/clrp-models/scaler/scaler_fold0\n",
      "/kaggle/input/clrp-models/scaler/scaler_fold3\n",
      "/kaggle/input/clrp-models/concat_model3/model.bin\n",
      "/kaggle/input/clrp-models/concat_model3/merges.txt\n",
      "/kaggle/input/clrp-models/concat_model3/tokenizer.json\n",
      "/kaggle/input/clrp-models/concat_model3/vocab.json\n",
      "/kaggle/input/clrp-models/concat_model3/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/concat_model3/special_tokens_map.json\n",
      "/kaggle/input/clrp-models/atPool_model0/model.bin\n",
      "/kaggle/input/clrp-models/atPool_model0/merges.txt\n",
      "/kaggle/input/clrp-models/atPool_model0/tokenizer.json\n",
      "/kaggle/input/clrp-models/atPool_model0/vocab.json\n",
      "/kaggle/input/clrp-models/atPool_model0/tokenizer_config.json\n",
      "/kaggle/input/clrp-models/atPool_model0/special_tokens_map.json\n",
      "/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n",
      "/kaggle/input/commonlitreadabilityprize/train.csv\n",
      "/kaggle/input/commonlitreadabilityprize/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52ce848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:18.170528Z",
     "iopub.status.busy": "2021-08-03T07:07:18.169691Z",
     "iopub.status.idle": "2021-08-03T07:07:27.350831Z",
     "shell.execute_reply": "2021-08-03T07:07:27.349739Z",
     "shell.execute_reply.started": "2021-08-03T06:24:57.019585Z"
    },
    "papermill": {
     "duration": 9.201218,
     "end_time": "2021-08-03T07:07:27.350986",
     "exception": false,
     "start_time": "2021-08-03T07:07:18.149768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from transformers import AutoModel,AutoConfig,AutoTokenizer,get_cosine_schedule_with_warmup\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9659740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.385071Z",
     "iopub.status.busy": "2021-08-03T07:07:27.384310Z",
     "iopub.status.idle": "2021-08-03T07:07:27.412099Z",
     "shell.execute_reply": "2021-08-03T07:07:27.411243Z",
     "shell.execute_reply.started": "2021-08-03T06:25:04.596073Z"
    },
    "papermill": {
     "duration": 0.046329,
     "end_time": "2021-08-03T07:07:27.412277",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.365948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "sample = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0384280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.448365Z",
     "iopub.status.busy": "2021-08-03T07:07:27.447349Z",
     "iopub.status.idle": "2021-08-03T07:07:27.451008Z",
     "shell.execute_reply": "2021-08-03T07:07:27.450484Z",
     "shell.execute_reply.started": "2021-08-03T06:25:04.617198Z"
    },
    "papermill": {
     "duration": 0.024339,
     "end_time": "2021-08-03T07:07:27.451165",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.426826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature(excerpt, stop_words):\n",
    "    dialogue_counts=excerpt.count('\"')/2\n",
    "    num_sentence = len(sent_tokenize(excerpt))\n",
    "    \n",
    "    words = word_tokenize(re.sub(\"[^a-zA-Z]\", \" \", excerpt).lower())\n",
    "    initial_num_words = len(words)\n",
    "    target_words = [word for word in words if word not in stop_words]\n",
    "    processed_num_words=len(target_words)\n",
    "    text_shrinkage = processed_num_words/initial_num_words\n",
    "    avg_sentence_length = initial_num_words / num_sentence\n",
    "    \n",
    "    return dialogue_counts, num_sentence, processed_num_words, text_shrinkage, avg_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4833ded4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.496153Z",
     "iopub.status.busy": "2021-08-03T07:07:27.495291Z",
     "iopub.status.idle": "2021-08-03T07:07:27.538634Z",
     "shell.execute_reply": "2021-08-03T07:07:27.538061Z",
     "shell.execute_reply.started": "2021-08-03T06:25:04.624972Z"
    },
    "papermill": {
     "duration": 0.073664,
     "end_time": "2021-08-03T07:07:27.538764",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.465100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"len\"] = test.excerpt.apply(len)\n",
    "test[\"excerpt\"] = test.excerpt.apply(lambda x: x.replace(\"\\n\",\" \"))\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "test['feature'] = test.excerpt.apply(feature, stop_words= stop_words)\n",
    "test[\"dialogue\"], test[\"num_sentence\"], test[\"num_processed_words\"], test['text_shrinkage'], \\\n",
    "test[\"avg_sentence_length\"] = zip(*test.feature)\n",
    "test.drop(columns=\"feature\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f46a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.626122Z",
     "iopub.status.busy": "2021-08-03T07:07:27.625071Z",
     "iopub.status.idle": "2021-08-03T07:07:27.632183Z",
     "shell.execute_reply": "2021-08-03T07:07:27.631556Z",
     "shell.execute_reply.started": "2021-08-03T06:30:07.114763Z"
    },
    "papermill": {
     "duration": 0.079759,
     "end_time": "2021-08-03T07:07:27.632327",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.552568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 2e-5,\n",
    "    'wd':0.01,\n",
    "    'batch_size':16,\n",
    "    'valid_step':10,\n",
    "    'max_len':500,\n",
    "    'epochs':5,\n",
    "    'nfolds':5,\n",
    "    'seed':9527,\n",
    "    'model_path':'../input/roberta-transformers-pytorch/roberta-base',\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7500f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.671870Z",
     "iopub.status.busy": "2021-08-03T07:07:27.669500Z",
     "iopub.status.idle": "2021-08-03T07:07:27.672985Z",
     "shell.execute_reply": "2021-08-03T07:07:27.673626Z",
     "shell.execute_reply.started": "2021-08-03T06:26:05.995034Z"
    },
    "papermill": {
     "duration": 0.027557,
     "end_time": "2021-08-03T07:07:27.673816",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.646259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer,feature,max_len=256, train=True):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.targets = df['target'].to_numpy()\n",
    "        self.feature = feature\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        \n",
    "        feature = torch.tensor(self.feature[idx],dtype=torch.float,)\n",
    "        \n",
    "        if self.train:\n",
    "            target = torch.tensor(self.targets[idx],dtype=torch.float) \n",
    "            return encode, feature, target\n",
    "        else:\n",
    "            return encode, feature\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9821f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.710145Z",
     "iopub.status.busy": "2021-08-03T07:07:27.709254Z",
     "iopub.status.idle": "2021-08-03T07:07:27.712883Z",
     "shell.execute_reply": "2021-08-03T07:07:27.712310Z",
     "shell.execute_reply.started": "2021-08-03T06:25:04.690357Z"
    },
    "papermill": {
     "duration": 0.024989,
     "end_time": "2021-08-03T07:07:27.713016",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.688027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,path):\n",
    "        super(Model,self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.config.update({'output_hidden_states':True,\"hidden_dropout_prob\": 0.0})\n",
    "        self.roberta = AutoModel.from_pretrained(path,config=self.config)\n",
    "        self.linear = nn.Linear(self.config.hidden_size*4+5, 1, 1)\n",
    "\n",
    "    def forward(self,feature, **xb):\n",
    "        x = self.roberta(**xb)\n",
    "        x = torch.stack(x[2])\n",
    "        x = torch.cat((x[-1], x[-2], x[-3], x[-4]),-1)\n",
    "        x = x[:, 0]\n",
    "        x = torch.cat((x,feature), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e65b7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.753243Z",
     "iopub.status.busy": "2021-08-03T07:07:27.752116Z",
     "iopub.status.idle": "2021-08-03T07:07:27.755268Z",
     "shell.execute_reply": "2021-08-03T07:07:27.755874Z",
     "shell.execute_reply.started": "2021-08-03T06:25:04.701255Z"
    },
    "papermill": {
     "duration": 0.028954,
     "end_time": "2021-08-03T07:07:27.756068",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.727114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "        score = self.V(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector\n",
    "    \n",
    "class ATHeadModel(nn.Module):\n",
    "    def __init__(self,path):\n",
    "        super(ATHeadModel,self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(path)  \n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.head = AttentionHead(self.config.hidden_size,self.config.hidden_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.config.hidden_size+5,1)\n",
    "\n",
    "    def forward(self,feature,**xb):\n",
    "        x = self.roberta(**xb)[0]\n",
    "        x = self.head(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat((x,feature), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc900bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.793040Z",
     "iopub.status.busy": "2021-08-03T07:07:27.791960Z",
     "iopub.status.idle": "2021-08-03T07:07:27.801821Z",
     "shell.execute_reply": "2021-08-03T07:07:27.801276Z",
     "shell.execute_reply.started": "2021-08-03T06:25:05.173194Z"
    },
    "papermill": {
     "duration": 0.031842,
     "end_time": "2021-08-03T07:07:27.801971",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.770129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionPoolingModel(nn.Module):\n",
    "    def __init__(self, path):\n",
    "        super(AttentionPoolingModel, self).__init__() \n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.config.update({'output_hidden_states':True,\"hidden_dropout_prob\": 0.0})\n",
    "        self.roberta = AutoModel.from_pretrained(path,config=self.config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.config.hidden_size+5,1)\n",
    "\n",
    "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.config.hidden_size))\n",
    "        self.q = nn.Parameter(torch.from_numpy(q_t).float())\n",
    "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.config.hidden_size, self.config.hidden_size))\n",
    "        self.w_h = nn.Parameter(torch.from_numpy(w_ht).float())\n",
    "\n",
    "    def forward(self, feature, **xb):\n",
    "        x = self.roberta(**xb)\n",
    "        x = torch.stack(x[2])\n",
    "        x = torch.stack([x[layer_i][:, 0].squeeze() for layer_i in range(1, self.config.num_hidden_layers+1)], dim=-1)\n",
    "        x = x.view(-1, self.config.num_hidden_layers, self.config.hidden_size)\n",
    "        x = self.attention(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat((x,feature), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def attention(self, h):\n",
    "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
    "        v = F.softmax(v, -1)\n",
    "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
    "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9e6ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.843141Z",
     "iopub.status.busy": "2021-08-03T07:07:27.842070Z",
     "iopub.status.idle": "2021-08-03T07:07:27.845747Z",
     "shell.execute_reply": "2021-08-03T07:07:27.845123Z",
     "shell.execute_reply.started": "2021-08-03T06:26:45.352121Z"
    },
    "papermill": {
     "duration": 0.028841,
     "end_time": "2021-08-03T07:07:27.845944",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.817103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prediction(df,Fold,MODEL,path,model_path,device='cuda'):\n",
    "    outputs = np.zeros(len(df))\n",
    "    for f in range(Fold):\n",
    "        model = MODEL(model_path)\n",
    "        model.load_state_dict(torch.load(path+f\"{f}/model.bin\",map_location=device))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        scaler = joblib.load(f\"../input/clrp-models/scaler/scaler_fold{f}\")\n",
    "        df_feature = scaler.transform(df.iloc[:,5:].to_numpy())\n",
    "\n",
    "        test_ds = CLRPDataset(df,tokenizer,df_feature, config['max_len'],train=False)\n",
    "        test_dl = DataLoader(test_ds,\n",
    "                            batch_size = config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers = 4,\n",
    "                            pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        predictions = list()\n",
    "        for i, (inputs, feature) in enumerate(test_dl):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(feature.to(device), **inputs)\n",
    "            outputs = outputs.cpu().detach().numpy().ravel().tolist()\n",
    "            predictions.extend(outputs)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        outputs+=np.array(predictions)\n",
    "    return outputs/Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5520e120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:07:27.879165Z",
     "iopub.status.busy": "2021-08-03T07:07:27.878306Z",
     "iopub.status.idle": "2021-08-03T07:09:29.556955Z",
     "shell.execute_reply": "2021-08-03T07:09:29.556076Z",
     "shell.execute_reply.started": "2021-08-03T06:30:26.033732Z"
    },
    "papermill": {
     "duration": 121.697101,
     "end_time": "2021-08-03T07:09:29.557168",
     "exception": false,
     "start_time": "2021-08-03T07:07:27.860067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer1=get_prediction(test,config[\"nfolds\"],Model,\"../input/clrp-models/concat_model\",config['model_path'],device)\n",
    "answer2=get_prediction(test,config[\"nfolds\"],ATHeadModel,\"../input/clrp-models/atHead_model\",config['model_path'],device)\n",
    "answer3=get_prediction(test,config[\"nfolds\"],AttentionPoolingModel,\"../input/clrp-models/atPool_model\",config['model_path'],device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f9732d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T07:09:29.595880Z",
     "iopub.status.busy": "2021-08-03T07:09:29.594620Z",
     "iopub.status.idle": "2021-08-03T07:09:29.603106Z",
     "shell.execute_reply": "2021-08-03T07:09:29.602467Z",
     "shell.execute_reply.started": "2021-08-03T06:31:16.432567Z"
    },
    "papermill": {
     "duration": 0.030511,
     "end_time": "2021-08-03T07:09:29.603245",
     "exception": false,
     "start_time": "2021-08-03T07:09:29.572734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer=(answer1+answer2+answer3)/3\n",
    "sample['target']=answer\n",
    "sample.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee86eaf",
   "metadata": {
    "papermill": {
     "duration": 0.014463,
     "end_time": "2021-08-03T07:09:29.632559",
     "exception": false,
     "start_time": "2021-08-03T07:09:29.618096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 143.843591,
   "end_time": "2021-08-03T07:09:33.016336",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T07:07:09.172745",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
